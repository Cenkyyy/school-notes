## 1. ZÃ¡klady strojovÃ©ho uÄenÃ­
------------------------------

### VysvÄ›tlit rozdÃ­ly mezi jednotlivÃ½mi typy strojovÃ©ho uÄenÃ­ (uÄenÃ­ s uÄitelem, bez uÄitele, zpÄ›tnovazebnÃ­ uÄenÃ­)
  - **uÄenie s uÄiteÄ¾om** - sÃº zadanÃ© objekty a k nim prÃ­sluÅ¡nÃ© vÃ½stupy. CieÄ¾om je nÃ¡jsÅ¥ model, ktorÃ½, ak mu je zadanÃ½ nejakÃ½ objekt, sprÃ¡vne priradÃ­ sprÃ¡vny vÃ½stup.
      
  - **uÄenie bez uÄiteÄ¾a** - sÃº zadanÃ© objekty bez poÅ¾adovanÃ½ch vÃ½stupov. CieÄ¾om je sa nauÄiÅ¥, ako vstupnÃ© objekty vyzerajÃº a generovaÅ¥ novÃ© objekty (generatÃ­vne modely), alebo napr. rozdeliÅ¥ objekty do skupÃ­n obsahujÃºcich podobnÃ© objekty (zhlukovanie).
  
  - **zpÄ›tnovazebnÃ© uÄenie** - snaÅ¾Ã­me sa nauÄiÅ¥ chovanie agenta, aby Äo najlepÅ¡ie rieÅ¡il zadanÃ½ problÃ©m na zÃ¡klade zpÃ¤tnej vÃ¤zby od prostredia, v ktorom sa pohybuje. Trial-and-error uÄenie, ohodnocujeme jeho akcie a na zÃ¡klade nich agenta penalizujeme alebo pochvÃ¡lime.  

### VysvÄ›tlit rozdÃ­ly mezi jednotlivÃ½mi Ãºlohami strojovÃ©ho uÄenÃ­ s uÄitelem (regrese, klasifikace)
  - Pri uÄenÃ­ s uÄiteÄ¾om mÃ´Å¾u byÅ¥ vÃ½stupy dvoch typov, buÄ kategorickÃ©, alebo ÄÃ­selnÃ©. Ak by Å¡lo o kategorickÃ©, tak je cieÄ¾om priradiÅ¥ objekt do sprÃ¡vnej kategÃ³rie (napr. rozhodnÃºÅ¥, Äi na obrÃ¡zku je pes alebo maÄka) a problÃ©m by sa nazÃ½val klasifikÃ¡ciou. Ak by Å¡lo o ÄÃ­selnÃ©, tak je cieÄ¾om na zÃ¡klade vstupnÃ½ch dat predpovedaÅ¥ ÄÃ­selnÃº hodnotu (napr. cenu nemovitosti na zÃ¡klade informÃ¡cii o nej), takÃ½to problÃ©m sa nazÃ½va regresia. 

### Popsat typy pÅ™Ã­znakÅ¯ (kategorickÃ©, ordinÃ¡lnÃ­, ÄÃ­selnÃ©) a jejich pÅ™edzpracovÃ¡nÃ­ (kÃ³dovÃ¡nÃ­ kategorickÃ½ch a ordinÃ¡lnÃ­ch pÅ™Ã­znakÅ¯, Å¡kÃ¡lovÃ¡nÃ­ ÄÃ­selnÃ½ch pÅ™Ã­znakÅ¯)
  - **kategorickÃ©** - reprezentujÃº kategÃ³rie bez nejakÃ©ho poradia (napr. Farba auta: ÄervenÃ¡, modrÃ¡...). Predspracovanie kategorickÃ½ch prÃ­znakov mÃ´Å¾e byÅ¥ napr. One-Hot encoding - Äo vlastne znamenÃ¡, Å¾e pre kaÅ¾dÃ½ stav kategÃ³rie si vytvorÃ­me binÃ¡rny znak, alebo Label encoding - kaÅ¾dÃ©mu stavu kategÃ³rie priraÄ unikÃ¡tne ÄÃ­slo
    
  - **ordinÃ¡lne** - ide vlastne o kategorickÃ© prÃ­znaky s poradÃ­m, napr. Hodnotenie: nÃ­zka kvalita < priemernÃ¡ kvalita < vysokÃ¡ kvalita. Predspracovanie ordinÃ¡lnych prÃ­znakov mÃ´Å¾e byÅ¥ napr. OrdinÃ¡lne - priraÄ kaÅ¾dej kategÃ³rii ÄÃ­selnÃº hodnotu.
      
  - **ÄÃ­selnÃ©** - ide o kvantitatÃ­vne hodnoty s ÄÃ­selnÃ½m vÃ½znamom, delÃ­me ich na **diskrÃ©tne** - poÄÃ­tateÄ¾nÃ© hodnoty (0, 1, 2..) a **spojitÃ©** - nekoneÄnÃ½ poÄet hodnÃ´t v intervale (170.2cm...). Predspracovanie ÄÃ­selnÃ½ch prÃ­znakov vyÅ¾aduje Å¡kÃ¡lovanie, prÃ­kladz Å¡kÃ¡lovanÃ­ mÃ´Å¾u byÅ¥ napr. Min-Max Scaling (normalizÃ¡cia do intervalu [0,1]) alebo naprÃ­klad Standard Scaling.

-------------------------
## 2. ZpÄ›tnovazebnÃ­ uÄenÃ­
-------------------------

### Popsat problÃ©m zpÄ›tnovazebnÃ­ho uÄenÃ­ intuitivnÄ› (agent, prostÅ™edÃ­, hledÃ¡nÃ­ strategie)
  - je to spÃ´sob uÄenia, kde sa agent uÄÃ­ optimÃ¡lneho chovania v svojom prostredÃ­ pomocou trail-and-error metÃ³dy
  - agent pozoruje stav prostredia, vykonÃ¡ akciu, dostane zpÃ¤tnÃº vÃ¤zbu (odmenu) a na zÃ¡klade nej si upravÃ­ svoje budÃºce chovanie
  - cieÄ¾om je nÃ¡jsÅ¥ stratÃ©giu, ktorÃ¡ maximalizuje celkovÃº odmenu
  - agent - entita/objekt, ktorÃ½ sa uÄÃ­ cez interakcie s prostredÃ­m
  - prostredie - vÅ¡etko, s ÄÃ­m agent dokÃ¡Å¾e interagovaÅ¥, obsahuje informÃ¡cie o stave
  - stav - popis aktuÃ¡lnej situÃ¡cie v prostredÃ­, ktorÃº agent popisuje
  - akcia - rozhodnutie agenta, ktorÃ© v nejakom stave vykonÃ¡
  - odmena - ÄÃ­selnÃ¡ hodnota poskytovanÃ¡ prostredÃ­m ako zpÃ¤tnÃ¡ vÃ¤zba za prevedenie nejakej akcie
### Popsat prostÅ™edÃ­ jako MarkovskÃ½ rozhodovacÃ­ proces
  - prostredie je nejakÃ¡ zadanÃ¡ Å¡tvorica **$(S,A,P,R)$**, kde:
    - **$S$** je koneÄnÃ¡ mnoÅ¾ina stavov prostredia
      
    - **$A$** je koneÄnÃ¡ mnoÅ¾ina akciÃ­

    - **$P_a(s,s')$** je prechodovÃ¡ funkcia, ktorÃ¡ udÃ¡va pravdepodobnosÅ¥, Å¾e aplikÃ¡cia akcie $a$ v stave $s$ prejde do prostredia v stave $s'$

    - **$R_a(s,s')$** je funkcia odmien, ktorÃ¡ udÃ¡va okamÅ¾itÃº odmenu, ktorÃº agent dostane od prostredia, ak je v stave $s$ a prevedie akciu $a$, kde nezÃ¡leÅ¾Ã­ na predchÃ¡dzajÃºcich stavoch a akciÃ¡ch - **MarkovskÃ¡ vlastnosÅ¥**!!!

  - **MarkovskÃ¡ vlastnosÅ¥** - budÃºcnosÅ¥ zÃ¡visÃ­ iba od aktuÃ¡lneho stavu a akcie, na predchÃ¡dzajÃºcich vÃ´bec nezÃ¡leÅ¾Ã­
  
  - chovanie agenta sa potom da popÃ­saÅ¥ ako strategia (policy) **$Ï€:SÃ—Aâ†’[0,1]$**, kde $Ï€(s,a)$ udÃ¡va pravdepodobnosÅ¥ prevedenia akcie $a$ v stave $s$

### Definovat zpÄ›tnovazebnÃ­ uÄenÃ­ jako problÃ©m hledÃ¡nÃ­ strategie maximalizujÃ­cÃ­ celkovou odmÄ›nu agenta
  - cieÄ¾om reinforcement learningu je potom najsÅ¥ strategiu $Ï€$ takÃº, Å¾e maximalizuje celkovÃº odmenu, ktorÃº agent zÃ­ska **$âˆ‘_{t=0...âˆ} Î³^t R_{a_t}(st,st+1)$**, kde **$a_t = Ï€(st)$** je akce provedenÃ¡ agentem v kroku $t$ a $Î³ < 1$ je diskontnÃ­ faktor, kterÃ½ zajiÅ¡Å¥uje, Å¾e suma je koneÄnÃ¡.

### Definovat pojmy hodnota stavu a hodnota akce
  - **hodnota stavu** - hodnota $V^Ï€(s)$ stavu $s$ pri pouÅ¾itÃ­ strategie $Ï€$ sa dÃ¡ definovaÅ¥ ako $V^Ï€(s) = E[R] = R[âˆ‘_{t=0...âˆ} Î³^t r_t|s_0 = s]$, kde $R$ znaÄÃ­ celkovÃº zÃ­skanÃº diskontovanÃº odmenu a $r_t$ znaÄÃ­ odmenu obdrÅ¾anÃº v Äase $t$.
  
  - **hodnota akce** - hodnota $Q^Ï€(s,a)$ akcie $a$ prevedednÃ¡ v stave $s$ ak budeme sledovaÅ¥ strategiu $Ï€$.  DÃ¡ sa to definovaÅ¥ ako $Q^Ï€(s,a) = E[âˆ‘_{t=0...âˆ} Î³^t r_t|s_0 = s,a_0 = a]$

### Popsat zÃ¡kladnÃ­ myÅ¡lenku Monte-Carlo metod (v rozsahu podle textu na webu)
  - ZpÄ›tnovazebnÃ­ uÄenÃ­ si lze pÅ™edstavit ve dvou krocÃ­ch - zlepÅ¡enÃ­ strategie a vyhodnocenÃ­ strategie.
    
  - Monte-Carlo metody sa pouÅ¾Ã­vajÃº pre vyhodnotenie strategie (odhad hodnoty funkcÃ­ ğ‘‰(ğ‘ ) a ğ‘„(ğ‘ ,ğ‘)):
    - Agent v stave $s$ vykonÃ¡ akciu $a$ podle strategie $ğœ‹$ dokÃ½m sa nedostane do nejakÃ©ho cieÄ¾a (vykonÃ¡va teda nejakÃº sekvenciu akcÃ­ - epizÃ³du akciÃ­).

    - ObdrÅ¾enou odmÄ›nu potom zaznamenÃ¡me, na konci epizÃ³dy.

    - VylepÅ¡enÃ­ strategie sa potom robÃ­ tak, Å¾e se spoÄÃ­tÃ¡ novÃ¡ (hladovÃ¡) stratÃ©gia na zÃ¡klade prÃ¡ve novÃ½ch hodnÃ´t $Q(s,a)$.
  
  - HlavnÃ½m problÃ©mom Monte-Carlo metod je, Å¾e ak sÃº rozptyly odmien pre akcie a stavy veÄ¾kÃ© tak bude konvergovaÅ¥ veÄ¾mi pomaly.

### VysvÄ›tlit Q-uÄenÃ­ (vÄetnÄ› vzorce pro aktualizaci matice Q)
  - je to off-policy metoda reinforcement learningu (nezavisÃ­ na Å¾iadnej konkrÃ©tnej strategie, ktorÃº agent sleduje), ktorÃ¡ nepotrebuje poznaÅ¥ model prostredia.

  - algoritmus je zaloÅ¾enÃ½ na temporal-difference (TD) metÃ³dach.
  
  - uÄÃ­ sa priamo funkciou $Q(s,a)$, v tradiÄnÃ½ch prÃ­padoch je $Q$ reprezentovanÃ¡ ako matica, na zaÄiatku inicializovanÃ¡ samÃ½mi nulami. NÃ¡sledne v kaÅ¾dom kroku agent pozoruje stav $s_t$ a prevedie akciu $a_t$, dostane odmenu $r_t$ a pozoruje novÃ½ stav $s_{t+1}$. Na zÃ¡klade tÃ½chto informÃ¡ciÃ­ sa maticu upravÃ­ nÃ¡sledovne: $Q^{new}(s_t, a_t) â† (1 - Î±)Q(s_t, a_t) + Î±(r_t + Î³ max_a Q(s_{t+1}, a))$, kde $Î±$ je parameter uÄenia a akcia $a_t$ mÃ´Å¾e byÅ¥ vybratÃ¡ Ä¾ubovoÄ¾nou metodou. 
  
  - vÃ½hoda oproti Monte Carlo metÃ³dam je, Å¾e sa pri jednom ohodnotenÃ­ upravÃ­ hodnota viacerÃ½ch stavov.

### Popsat algoritmus SARSA (State-Action-Reward-State-Action)
  - obdobnÃ½ Q-uÄeniu, ale vÃ½poÄet Q sa prevÃ¡dza podÄ¾a vzÅ¥ahu: $Q(s_t, a_t) â† Q(s_t, a_t) + Î±[r_t + Î³ Q(s_{t+1}) - Q(s_t, a_t)]$, kde $a_t$ a $a_{t+1}$ sÃº zaloÅ¾enÃ© na strategii pouÅ¾Ã­vanej agentom, teda ide o on-policy algoritmus.

### VysvÄ›tlit, jak pouÅ¾Ã­t Q-uÄenÃ­ v prostorech se spojitÃ½mi stavy a akcemi
  - problÃ©m implementÃ¡cie Q-uÄenia cez maticu je ten, Å¾e funguje len na diskrÃ©tnÃ½ch priestoroch a s diskrÃ©tnÃ½mi akciami, teda v prÃ­pade spojitÃ½ch stavov a akciÃ­ sa dÃ¡ postupovaÅ¥ nÃ¡sledovne:
      
      - **stavy a akcie diskretizujeme** - napr. na Mountain Car mÃ´Å¾eme hodnoty polohy a rÃ½chlosti rozdeliÅ¥ do intervalov a stav reprezentovaÅ¥ intervalom, miesto konkrÃ©tnej hodnoty. V prÃ­pade akcÃ­Ã­ to budeme rieÅ¡iÅ¥ podobne.
  
  - ÄalÅ¡Ã­m problÃ©mom mÃ´Å¾e byÅ¥ veÄ¾kosÅ¥ matice pre stavovÃ© priestory, potom sa algoritmus uÄÃ­ veÄ¾mi pomaly, alebo vÃ´bec.
      
      - dÃ¡ sa to vyrieÅ¡iÅ¥ tak, Å¾e pouÅ¾ijeme inÃ© metÃ³dy, ktorÃ© sa uÄia priamo mapovanie zo stavu na akciu, s tÃ½mi nÃ¡sledne spojitÃ© akcie problÃ©m vaÄÅ¡inou nemajÃº a taktieÅ¾ ani veÄ¾kosÅ¥ stavu.

-------------------------------------
## 3. JednoduchÃ½ genetickÃ½ algoritmus
-------------------------------------

#### Princip
  - JednoduchÃ½ genetickÃ½ algoritmus funguje na princÃ­pe selekcie najlepÅ¡Ã­ch jedincov, ktorÃ­ sa Äalej rozmnoÅ¾ujÃº pomocou genetickÃ½ch operÃ¡torov, ÄÃ­m vznikajÃº novÃ© generÃ¡cie jedincov lepÅ¡ie adaptovanÃ½ch na danÃ½ problÃ©m.

### Popsat zÃ¡kladnÃ­ verzi evoluÄnÃ­ho algoritmu s binÃ¡rnÃ­m kÃ³dovÃ¡nÃ­m
  - JednoduchÃ½ genetickÃ½ algoritmus pouÅ¾Ã­va reprezentÃ¡ciu jedinca ako binÃ¡rny reÅ¥azec pevnej dÄºÅ¾ky. KaÅ¾dÃ½ bit predstavuje jednu vlastnosÅ¥ rieÅ¡enia.

  - Postup algoritmu:
    - InicializÃ¡cia populÃ¡cie â€“ populÃ¡cia sa generuje nÃ¡hodne.

    - VÃ½poÄet fitness funkcie â€“ hodnotÃ­ sa kvalita kaÅ¾dÃ©ho jedinca.

    - Selekcia rodiÄov â€“ jedinci sa vyberajÃº podÄ¾a urÄitej stratÃ©gie (pomocou ruletovej alebo turnajovej selekcie)  jedinci mÃ´Å¾u byÅ¥ vybranÃ­ opakovane. 

    - AplikÃ¡cia genetickÃ½ch operÃ¡torov na vybranÃ½ch rodiÄov (jedincov):
        - KÅ™Ã­Å¾enÃ­ (crossover) â€“ kombinovanie dvoch rodiÄov na vytvorenie novÃ½ch jedincov.
        
        - MutÃ¡cia â€“ nÃ¡hodnÃ¡ zmena niektorÃ½ch bitov na zabezpeÄenie diverzity, aplikuje sa po krÃ­Å¾enÃ­

    - Tvorba novej generÃ¡cie â€“ novÃ½ potomkovia nahradia predchÃ¡dzajÃºcu populÃ¡ciu

    - Opakovanie cyklu â€“ algoritmus pokraÄuje, kÃ½m nie je splnenÃ© kritÃ©rium zastavenia (napr. maximÃ¡lny poÄet iterÃ¡ciÃ­ alebo konvergencia na optimÃ¡lne rieÅ¡enie).
   
### Popsat zÃ¡kladnÃ­ genetickÃ© operÃ¡tory (jednobodovÃ©, n-bodovÃ© kÅ™Ã­Å¾enÃ­, mutace)
  - **jednobodovÃ© krÃ­Å¾enie** - nÃ¡hodne sa vyberie jeden bod v jedincovi a novÃ½ potomok vznikne tak, Å¾e sa skopÃ­ruje ÄÃ¡sÅ¥ z jedneho rodiÄa pred tÃ½mto bodom a z druhÃ©ho rodiÄa od toho bodu Äalej.
  
  - **n-bodovÃ© krÃ­Å¾enie** - podobne ako jednobodovÃ©, ale existuje viacero bodov zmeny. Potomci teda vznikajÃº tak, Å¾e sa alternuje, z akÃ©ho rodiÄa je vybratÃ¡ akÃ¡ ÄÃ¡sÅ¥.

  - **uniformnÃ© krÃ­Å¾enie** - u kaÅ¾dej pozÃ­cie sa znova nÃ¡hodne rozhodneme, z ktorÃ©ho rodiÄa dosadÃ­me hodnotu do potomka.
  
  - **mutÃ¡cia** - nÃ¡hodnÃ¡ zmena niektorÃ½ch bitov na zabezpeÄenie diverzity, v prÃ­pade binÃ¡rneho kÃ³dovania ide o preklopenie bitov.
 
### Popsat ruletovou a turnajovou selekci
  - **ruletovÃ¡ selekcia** - pravdÄ›podobnost vÃ½bÄ›ru danÃ©ho jedince je pÅ™Ã­mo ÃºmÄ›rnÃ¡ jeho fitness. FormÃ¡lne pravdepodobnosÅ¥ $p_i$, Å¾e si alg. vyberie jedinca $i$ sa spoÄÃ­ta ako $p_i = \frac{f_t}{âˆ‘_{j=1...N}f_j}$, kde $f_j$ je fitness jedinca $j$
  
  - **turnajovÃ¡ selekcia** - z populÃ¡cie sa nÃ¡hodne vyberie podmnoÅ¾ina jedincov (typicky 2) a najlepÅ¡Ã­ z nich (porovnanÃ­m ich fitness) s veÄ¾kou pravdepodobnosÅ¥ou (napr. 80%) postÃºpi do ÄalÅ¡ej generÃ¡cie.
    
### VysvÄ›tlit vÃ½hody a nevÃ½hody turnajovÃ© a ruletovÃ© selekce
  - vÃ½hody:

    - ruletovÃ¡ selekcia: jednoduchÃ¡ implementÃ¡cia, funguje fajn pre rozumnÃ½ rozsah fitness hodnÃ´t

    - turnajovÃ¡ selekcia: funguje aj pri zÃ¡pornÃ½ch fitness hodnotÃ¡ch. ZÃ¡leÅ¾Ã­ len na poradÃ­ jedincov podÄ¾a fitness.
  
  - nevÃ½hody:

    - ruletovÃ¡ selekcia: zÃ¡leÅ¾Ã­ priamo na hodnotÃ¡ch fitness, teda ak fitness zmenÃ­me tak, Å¾e k nej pripoÄÃ­tame nejakÃº nÃ¡hodnÃº konÅ¡tantu, tak sa zaÄne chovaÅ¥ nÃ¡hodne.

    - turnajovÃ¡ selekcia: pri zlom nastavenÃ­ veÄ¾kosti turnaja mÃ´Å¾e prÃ­sÅ¥ k rÃ½chlej konvergencii na nie optÃ­malne rieÅ¡enie.

### VysvÄ›tlit, co je fitness funkce
  - je to hodnotiaca funkcia, ktora kazdemu jedincovi v populacii priradi ciselnu hodnotu podla kvality jeho riesenie daneho problemu. Typicky sa tato fitness funkcia maximalizuje, teda cim vacsia hodnota, tym lepsi jedinec, ale existuju aj minimalizacne problemy.

### Popsat elitismus
  - elitismus znamenÃ¡, Å¾e sa najlepÅ¡Ã­ jedinci automaticky prenesÃº do ÄalÅ¡ej generÃ¡cie bez aplikÃ¡cie genetickÃ½ch oprÃ¡torov, ÄÃ­m sa vlastne nestratia najlepÅ¡ie rieÅ¡enia. NÃ¡sledne je potom potreba uÅ¾ len vybraÅ¥ toÄ¾ko potomkov, aby sa populÃ¡cia naplnila, pretoÅ¾e sa v jednoduchom genetickom algoritme poÄet rodiÄov a potomkov musÃ­ rovnaÅ¥ (aÅ¾ na daÄ¾Å¡i bod).
    
### Popsat metody pro environmentÃ¡lnÃ­ selekci (pÅ™enos jedincÅ¯ do dalÅ¡Ã­ populace), (Î¼,Î») a (Î¼+Î»)
  - (Î¼,Î»): do novej populacie sa vybera Î¼ najlepsich jedincov len spomedzi Î» potomkov, rodicia su uplne odstraneni. Potrebne aby Î» > Î¼.

  - (Î¼+Î»): do novej populacie sa vybera Î¼ najlepsich jedincov spomedzi Î¼ rodicov a Î» potomkov. Zarucuje elitismus, najlepsi jedinec nemoze byt prehliadnuty.

### Popsat rozÅ¡Ã­Å™enÃ­ jednoduchÃ©ho GA na problÃ©my s celoÄÃ­selnÃ½m kÃ³dovÃ¡nÃ­m

  - Typicky len miesto vektoru 0 a 1-tiek pouzijeme vektor celych cisel o pevnej dlzke ako reprezentaciu jedinca

  - Operatory:
    - Krizenie: moze ostat rovnake, jednobodove, n-bodove, uniformne nad celociselnymi vektormi
    - Mutacie: napr. nahodne zmenine nejaku hodnotu na inu, ale k nej priratame/odcitame nejaku konstantu

--------------------------------------------------
## 4. EvoluÄnÃ­ algoritmy pro spojitou optimalizaci
--------------------------------------------------

### Definovat problÃ©m spojitÃ© optimalizace

  - Problem spociva v hladani globalneho extremu (typicky minima) realnej funkcie f:$R^n$ -> $R$.

  - Hladame teda vektor $x$, pre ktory plati: $x^* = arg min f(x)$ z definicneho oboru $D$.

  - Typicke pri ladeni parametrov, trenovani modelov alebo optimalizacii technologickych procesov.

### Popsat genetickÃ© operÃ¡tory pouÅ¾Ã­vanÃ© ve spojitÃ© optimalizaci - aritmetickÃ© kÅ™Ã­Å¾enÃ­, zatÃ­Å¾enÃ© a nezatÃ­Å¾enÃ© mutace

  - Mutacia:
    - Nezatizena: Nahradenie hodnoty na vybranej pozicii novou nahodnou hodnotou z nejakeho intervalu
      
    - Zatizena: Nova hodnota vychadza z povodnej hodnoty (napr. Gaussovska mutacia - k danemu cislu pricita hodntou z normalneho rozdelenia so strednou hodnotu 0 a nejakym rozptylom)
   
  - Krizenie:
    - Mozeme pouzit klasicke n-bodove krizenie

    - Aritmeticke krizenie: potomok sa ziska ako vazeny priemer rodicov. 

### VysvÄ›tlit rozdÃ­l mezi separabilnÃ­mi a neseparabilnÃ­mi funkcemi

  - Separabilne funkcie: Dokazu sa optimalizovat nezavisle po jednotlivych zlozkach. To znamena ze pre kazdu premennu zvlast dokazeme najst jej optimum

  - Neseparabilne funkcie: Medzi premennymi existuju interakcie, zmena jednej premennej ovplvni zavislost na ostatnich.

### Popsat algoritmus diferenciÃ¡lnÃ­ evoluce a jeho vÃ½hody

  - Je to evolucny algoritmus pre spojitu optimalizaciu

  - Mutacia: k jedincovi pricita rozdiel dvoch nahodnych jedincov z populacie

  - Krizenie Uniformne krizenie s dalsim nahodnym jedincom

  - Selekcia: Potomok sa porovna s rodicom a v populacii sa necha lepsi z nich

  - Vyhody: Invariantnost voci rotaciam a skalovaniu priestoru, nevadia jej neseparabilne funkcie, lahka implementacia

---------------------------------------------------------
## 5. EvoluÄnÃ­ algoritmy pro kombinatorickou optimalizaci
---------------------------------------------------------

### Popsat mutace pro permutaÄnÃ­ kÃ³dovÃ¡nÃ­

  - Musi sa zachovat permutacia, teda napriklad mozne mutacie mozu byt:
    - Swapping: Prehodenie dvoch nahodne vybranych pozicii
    - Inversion: Nahodne otocime usek permutacie
    - Insertion: Zoberieme prvok z nejakej pozicie a vlozime ho na inu

### Popsat kÅ™Ã­Å¾enÃ­ pouÅ¾Ã­vanÃ¡ pÅ™i permutaÄnÃ­m kÃ³dovÃ¡nÃ­ (OX, PMX, ER)

  - OX (Order crossover):
    - Zvolia sa dva body
    - Strednne casti sa zamenia
    - Zbytok je doplneny v rovnakom poradi ako v druhom rodicovi, ale vynechaju sa duplicity (zaciname od druheho bodu)
   
    - 12|345|678      ..|186|...      45|186|723 (pÅ™eskakujeme ÄÃ­sla 186)  
    - 34|186|527      ..|345|...      86|345|271 (pÅ™eskakujeme ÄÃ­sla 345)

  - PMX (Partially Mapped crossover):
    - Zvolia sa dva body
    - Stredne casti sa zamenia
    - Hodnoty, ktore neboli zamenene v strede ostanu sa svojich poziciach
    - Ak vzniknu duplicity, nahradime ich podla pozicii hodnot v strednych castiach (zo zamenenho stredu na povodny stred)
   
    - 12|345|678      .2|186|.7.      32|186|574 (1->3, 6->5, 8->4)
    - 34|186|527      ..|345|.27      18|345|627 (3->1, 4->8, 5->6) 

  - ER (Edge recombination):
    - Funguje specialne pre problem obchodneho cestujuceho
    - Zostavi sa zoznam susedov kazdeho vrcholu z oboch rodicov
    - Zacneme vrcholov s najmensim poctom susedov
    - Iterativne sa vyberie dalsi vrchol s najkratsim zoznamom susedov
    - Susedov aktualizujeme tak, ze odoberieme tych, ktori uz su pouziti.

### VysvÄ›tlit pouÅ¾itÃ­ evoluÄnÃ­ch algoritmÅ¯ pro problÃ©m obchodnÃ­ho cestujÃ­cÃ­ho

  - Problem hlada najkratsi cyklus cez vsetky vrcholy uplneho grafu
  - Jedinec je reprezentovany ako permutacia vrcholov
  - Permutacia hovori v akom poradi ma jedinec jednotlive vrcholy navstivit

-------------------------------------------------
## 6. LineÃ¡rnÃ­ a kartÃ©zskÃ© GP, gramatickÃ¡ evoluce
-------------------------------------------------

- Geneticke programovanie: technika, ktora umoznuje pomocou evolucnych algoritmov automatiky vytvarat programy

### Popsat lineÃ¡rnÃ­ genetickÃ© programovÃ¡nÃ­ (kÃ³dovÃ¡nÃ­ jedince, operÃ¡tory)

- Jedinec je reprezentovany ako postupnostou intrukcii

- Kazda instrukcia moze manipulovat s registrami, datovym polom, vstupmi a vystupmi (priklad: `input / 0 / save / input / add / output`)

- Geneticke operatory:
  - Mutacia: nahradime jednu instrukciu inou nahodne zvolenou
 
  - Krizenie: skombinujeme casti instrukcii z dvoch rodicov - napr. 1-bodovy crossover

### Popsat kartÃ©zskÃ© genetickÃ© programovÃ¡nÃ­ (kÃ³dovÃ¡nÃ­ jedince, operÃ¡tory)

- Program je zadany na mriezke $r x l$, ktora ma $r$ riadkov a $l$ vrstiev (stlpcov)

- Jedinec je vektor $r x l$ genov

- Gen sa sklada z dvoch casti - kodu (mena) funckie, ktoru pocita a indexov do predchadzajucich vrstiev, z ktorych berie vstupy

- Geneticke operatory:
  - Mutacia:
      - Zmena funkcie na inu
      - Zmena vstupov funkcie
      - Zmena vystupov programu
 
  - Krizenie: obvykle sa nepouziva

### Popsat gramatickou evoluci (kÃ³dovÃ¡nÃ­ jedince, operÃ¡tory)

- Jedinec je postupnost celych cisel, ktora urcuje, ktore pravidlo z gramatiky sa ma pouzit pre prepis aktualneho prveho neterminalu (cez operaciu `index % pocet_pravidiel`)

- Pouziva sa bezkontextova gramatika ako syntax programovacieho jazyka

- Geneticke operatory:
  - Mutacia: Zmena niektorych cisel v postupnosti cisel
 
  - Krizenie:
    - Klasicke n-bodove krizenie
    - Krizenie, ktore vyberie z kazdeho jedinca gen, kde sa zacina zpracovavat nejaky neterminal a prehodi ho s poziciou v druhom jedincovi, kde sa objavi ten isty neterminal. Vyhoda: zachovanie semantickosti a stale mame validneho potomka

### VysvÄ›tlit, jak Å™eÅ¡it problÃ©m s pÅ™Ã­liÅ¡ krÃ¡tkÃ½m nebo dlouhÃ½m jedincem v gramatickÃ© evoluci

- Ak je jedinec prilis kratky - tak nemusi byt vyhodnotitelny, mozu v nom ostat neterminaly:
  - Ako riesenie sa snazime generovat dlhsich jedincov, ak jedinec nepouzije niektore svoje geny nie, tak to az tak nevadi.

- Ak je jedinec prilis dlhy - tak mame zbytocne geny naviac:
  - Ako riesenie mozeme geny ignorovat, alebo ich pripadne zmazat

-------------------------------------
## 7. StromovÃ© genetickÃ© programovÃ¡nÃ­
-------------------------------------

### Popsat stromovÃ© genetickÃ© programovÃ¡nÃ­ a jeho genetickÃ© operÃ¡tory

- Reprezentacia jedinca
  - Jedinec je strom
  - Uzly - funkcie (napr. +, *, if, and, or,...) - neterminaly
  - Listy - terminaly (napr. vstupy, konstanty)

- Vyhodnotovanie prebieha rekurzivne od listov ku korenu

- Hodnota korena je vystup programu

- Geneticke operatory:
  - Mutacia:
    - Zmena funkcie/terminalu na iny
    - Nahradenie podstrou novym nahodnym
    - Redukcia podstromu na terminal
 
  - Krizenie: Vymena podstromov medzi dvoma jedincami

### Popsat prÃ¡ci s konstantami ve stromovÃ©m genetickÃ©m programovÃ¡nÃ­

- Nie je mozne dat vsetky cisla medzi terminaly, bolo by ich vela

- Casto sa zadaju len tie zakladne konstanty (0,1,2, apod.) a predpoklada sa, ze dalsie hodnoty si program dokaze spocitat sam z nich

- Druha moznost je mat specialne opratory, ktore menia hodnoty konstant podobne ako v spojitej optimalizacii

### Popsat typovanÃ© genetickÃ© programovÃ¡nÃ­

- Kazda funkcia ma presne definovane typy vstupov a vystupov, napr. `add: int x int -> int`

- Potom sa stromy generuju a upravuju tak, aby boli typovo korektne

- Vyhoda: Zabranime typ vzniku nevalidnych stromov, vacsia prehladnost

### Popsat automaticky definovanÃ© funkce

- Geneticke programovanie moze vytvarat a pouzivat vlastne funkcie (subprogramy)

- Tieto funkcie su ulozene v oddelenej casti jedinca

- Hlavny program (strom) moze volat automaticky definovane funkcia ako bezne funkcie

- Kazda automaticky definovana funkcia ma svoj vlastny strom, omedzene vstupy a definovane telo

### VysvÄ›tlit, jak u automaticky definovanÃ½ch funkcÃ­ zabrÃ¡nit zacyklenÃ­/nekoneÄnÃ© rekurzi

- Zakazat rekurzivne volania automaticky definovanych funkcii

- Omedzit hlbku volania funkcii

### Porovnat jednotlivÃ© typy genetickÃ©ho programovÃ¡nÃ­ a jejich vÃ½hody/nevÃ½hody

- Linearne GP:
  - Vyhody: Blizko realnym programom, jednoduche operatory, jazyk
  - Nevyhody: Mensia flexibilita

- Kartezske GP:
  - Vyhody: Prehladna struktura
  - Nevyhody: Tazsie krizenie - nepouziva sa

- Gramaticka evolucia:
  - Vyhody: Zarucena syntakticka spravnost
  - Nevyhody: Problem s dlzkou jedinca (prilis kratky/dlhy)

- Stromove GP:
  - Vyhody: Lahka vizualizacia, garantovana korektnost ak pouzivame typovanost, prirodzenost, lahko vypocitatelne
  - Nevyhody: Typovanie, Ako reprezentovat pociatocnu populaciu (dany pocet neterminalov/v danej hlbke vzdy pouzit terminal...), riziko zacyklenia ak pouzijeme automaticky definovane funkcie

----------------------------------
## 8. PerceptronovÃ© neuronovÃ© sÃ­tÄ›
----------------------------------

- pouzivaju sa casto pre klasifikaciu alebo regresiu v strojovom uceni

### Popsat, jakÃ½m zpÅ¯sobem poÄÃ­tÃ¡ jeden perceptron

- zakladna jednotka v neuronovej sieti

- perceptron je jednoduchy model umeleho neuronu, ktory prijima vstupny vektor $x = (x_1,...,x_n)$, priradene vahy $w = (w_1,...,w_n)$ a pocita jeden vystup $y$ podla:
  - $Î¾ = \sum_{i = 1}^n w_i x_i + b$
  - $y = f(Î¾)$
  - kde $b$ je bias, ktory ovplyvnuje, nakolko musi byt vazeny sucet vacsi ako 0, aby sa perceptron aktivoval a $f$ je aktivacna funkcia
 
  - taktiez druha moznost je pridat bias ako dalsi vstup s konstantnou hodnotou 1, vypocet perceptronu potom vyzera takto: $f(\sum_{i=0}^n w_i f_i)$, kde $f$ je funkcia, ktora pre $x<0$ vrati 0, inac 1.
 
  - taktiez existuje funkcia, ktora miesto 0 a 1 vracia -1 a 1, rozdiel je len vo funkcii.

### Popsat algoritmus pro trÃ©novÃ¡nÃ­ perceptronu a vysvÄ›tlit, kdy konverguje

- perceptrony trenujeme tak, ze postupne sa predkladaju vstupy (x,y), z trenovacej mnoziny, kde x je vstup a y je pozadovany vystup a:
  - vahy aktualizujeme: $w_i$ <- $w_i + r(y-f(x))x_i$
  - kde $r$ je learning rate, ako rychlo sa meni vahovy vektor

- perceptron konverguje, ak su triedy v datach linearne separabilne, teda z nich dokazeme oddelit nadrovinu v vstupnom priestore

### Popsat strukturu vÃ­cevrstvÃ½ch perceptronovÃ½ch sÃ­tÃ­

- struktura sa sklada z:
  - vstupnej vrstvy - vstupne data su priamo z trenovacej mnoziny
  - jednej alebo viacerych skrytych vrstiev - vstupy su vystupy z predoslej vrstvy
  - vystupnej vrstvy - neurony produkujuce vystup, vstupy su vystupy z predoslej vrstvy
 
- spojenie je dopredne (feedforward), ziadne cykly, tie su az v rekurentnych neuronovych sietach

### Popsat aktivaÄnÃ­ funkce pouÅ¾Ã­vanÃ© ve vÃ­cevrstvÃ½ch perceptronech (sigmoida, tanh, ReLU)

- sigmoida:
  - pouzivaju sa najma v starsich sietach
 
  - $f(x) = \frac{1}{1 + e^{-Î»x}}$

- tanh:
  - vystup [-1,1], symetricka okolo nuly, casto sa povazuje za vhodnejsiu ako sigmoida
 
  - $f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$

- ReLU (Rectified Linear Unit):
  - vyhodou je jednoduchy vypocet
 
  - $f(x) = max(0, x)$

### Popsat metodu pro trÃ©novÃ¡nÃ­ neuronovÃ½ch sÃ­tÃ­ (backpropagation)

- ciel je minimalizovat chybovu funkciu $L(x,y|w) (napr. MSE - mean squared error)

- backpropagation funguje tak, ze:
  - najprv postupuje ako feedforward siet, kedy ziskame nejaky vystup k danym vstupom
  - potom si zratame tzv. loss function, ktora je rozdielom aktualneho vystupu od ocakavaneho
  - potom sa vraciame spat a snazime sa opravit vahy medzi neuronmi pomocou gradient descend algoritmu tak, aby vystup uz bol spravny
 
- gradient descend algoritmus   

  - dopredny vypocet: zrata vystupy vsetkych vrstiev
  - vypocet chyby vystupu: porovna vystup siete s cielom
  - zpetny prechod: spocitaj gradienty podla retazoveho pravidla
  - aktualizacia vah: $w_ij^{(l)}$ <- $w_ij^{(l)} - Î± \frac{âˆ‚E}{âˆ‚w_ij^{(l)}}$

- pouziva sa gradientny zostup
  

### Odvodit pravidla pro adaptaci vah v metodÄ› zpÄ›tnÃ©ho Å¡Ã­Å™enÃ­ (alespoÅˆ pro vÃ½stupnÃ­ vrstvu + ideu pro skrytÃ© vrstvy)

- 

--------------
## 9. RBF sÃ­tÄ›
--------------

### Popsat RBF jednotku a architekturu RBF sÃ­tÄ›

- RBF jednotka (radial basis function neuron) je specialny typ neuronu, ktory sa aktivuje na zaklade vzdialenosti vstupu od tzv. stredu neuronu. Hodnoti, ako "blizko" je vstup od nejakeho reprezentovaneho bodu, formalne: $y = Ï(âˆ¥xâˆ’câˆ¥)$, kde $x$ je vstupny vektor, $c$ je stred neuronu, $Ï$ je aktivacna funkcia, typicky Gaussovska: $p(x) = e^{-Î²x^2}$

- Architektura RBF siete:
  - 1. vrstva: RBF vrstva, ktora pozostava z RBF jednotiek
  - 2. vrstva: vrstva neuronov (perceptronoveho typu)
  - vystup celej siete: $Ï†(x) = \sum_{i=1}^N w_i Ï(âˆ¥xâˆ’c_iâˆ¥)$, kde $w_i$ su vahy pre vystupnu vrstvu

### VysvÄ›tlit princip trÃ©novÃ¡nÃ­ RBF sÃ­tÃ­

- trening RBF siete prebieha typicky v dvoch fazach:
  1. Vyber stredov (centier) RBF neuronov: pomocou algoritmu k-means sa zhlukuju vstupy do k skupin, stredy tychto zhlukov sa stanu stredmi RBF neuronov $c_i$. Potom spocitame parameter $Î²$ v kazdom neurone ako $Î² = \frac{1}{2Ïƒ^2}$, kde $Ïƒ$ je priemerna vzdialenost objektov v prislusnom zhluku. 

  3. Trening vah vystupnej vrstvy: kedze vystupna vrstva je linearna, mozeme pouzit linearnu regresiu, alebo ak je viac vystupov, maticovu regresiu

### Popsat algoritmus k-means

- Je to algoritmus pre zhlukovanie (ucenie bez ucitela):
  - algoritmus dostane na vstupe vektory dat $x_i$ a cislo $k$, ktore je pocet zhlukov
  - Inicializujeme $k$ nahodnych centier (napr. nahodne vzorky zo vstupu)
  - Opakujeme:
    - Priradenie: kazdy vstupny vektor sa priradi k najblizsiemu stredu
    - Prepocitanie centier: nove centrum kazdeho zhluku je aritmeticky priemer bodov v danom zhluku
  - konvergencia: ked sa centra prestanu menit alebo po danom pocte iteracii 

### Porovnat geometrickÃ© vlastnosti RBF sÃ­tÃ­ a vÃ­cevrstvÃ½ch perceptronÅ¯

-

----------------------
## 10. KonvoluÄnÃ­ sÃ­tÄ›
----------------------

- siete, ktore dostavaju ako vstupy obrazky

### Popsat funkci konvoluÄnÃ­ho filtru

- Konvolucny filter je mala matica (napr. 3x3), ktora sa "posuva" po obrazku a na kazdom mieste vykonava konvolucnu operaciu - teda vypocet skalarneho sucinu medzi hodnotami pixelov v okienku obrazka a hodnotami filtra (vah)
  - zachytava lokalne obrazove vzory (hrany, texturu, rohy)
  - ma zdielane vahy: roznaky filter sa aplikuje na vsetky pozicie
  - je vypoctovo efektivna
  - vystupom je feature mapa, ktora zvyraznuje vyskyt daneho vzoru v roznych castiach obrazku

### Popsat funkci pooling vrstev v konvoluÄnÃ­ sÃ­ti

- pooling vrstvy redukuju rozlisenie obrazu a tym:
  - znizuju vypoctovu narocnost
  - ulahcuju extrakciu globalnych crt
 
- najcastie pouzivany typ pooling funkcie je max-pooling, ktory pre kazde podokno (napr. 2x2) v obraze vezme maximum z hodnot v tejto oblasti. Typicky sa tieto okna neprekryvaju.

### Popsat architekturu konvoluÄnÃ­ neuronovÃ© sÃ­tÄ›

- architektura pozostava z opakovania blokov:
  - konvolucna vrstva (feature extrakcia)
  - ReLU aktivacia
  - pooling
- na konci funkcia pre klasifikaciu, napr softmax

### VysvÄ›tlit, co jsou matoucÃ­ vzory a jak ovlivÅˆujÃ­ praktickÃ© nasazenÃ­ neuronovÃ½ch sÃ­tÃ­

- matuce vzory su obrazky, ktore boli zamerne jemne upravene tak, ze:
  - pre cloveka sa zmeny zdaju neviditelne
  - ale neuronova siet ich klasifikuje nespravne
 
- prakticky to znizuje spolahlivost neuronovych sieti v citlivych oblastiach ako: autonomne vozidla, medicina

### Popsat algoritmus FGSM pro vytvÃ¡Å™enÃ­ matoucÃ­ch vzorÅ¯

- FSGM (Fast Gradient Sign Method) je jednoduchy a efektivny sposob, ako vytvorit matuce vzory.

- spocita derivaciu chybovej funkcie podla vstupu neuronovej siete a pripocita k tomuto vstupu $Îµ sign(âˆ‡J)$, kde $âˆ‡J$ je gradient, uz len pre $Îµ < 0.1$ moze lahko zmiast vela modelov neuronovych sieti, ktore davaju dobre vysledky

### VysvÄ›tlit myÅ¡lenku pÅ™enosu umÄ›leckÃ©ho stylu

- prenos umeleckeho stylu znamena vytvorenie noveho obrazku, ktory:
  - ide o optimalizacny problem kde sa:
    - zachovava obsah povodneho obrazku
    - ale prevezme styl ineho obrazu (napr. Picasso)

### VysvÄ›tlit zÃ¡kladnÃ­ fungovanÃ­ generative adversarial networks (podle rozsahu v textu na webu)

- je architektura dvoch sutaziacich neuronovych sieti:
  - Generator:
    - ma za ulohu generovat obrazky, ktore su podobne obrazkom v nejakej trenovacej mnozine
    - ciel je potom maximalizovat chybu diskriminatoru
  
  - Diskriminator:
    - ma za ulohu poznat, ci predlozeny obrazok je generovany generatorom, alebo ci pochadza z trenovacej mnoziny
    - ciel je minimalizovat svoju chybu

- po trenovani sa vyuziva len generator

--------------------------------
## 11. RekurentnÃ­ neuronovÃ© sÃ­tÄ›
--------------------------------

### Definovat, co jsou rekurentnÃ­ neuronovÃ© sÃ­tÄ›

- su take neuronove siete, v ktorych existuju cyklicke vazby medzi neuronmi, teda vahy vedu spat do predchadzajucich stavov. Vdaka tomu si siet pamata predchadzajuce vstupy, teda ma vlastny vnutorny stav

### VysvÄ›tlit, kde se rekurentnÃ­ sÃ­tÄ› pouÅ¾Ã­vajÃ­

- Pouzivaju sa vsade tam, kde je vstup sekvencny alebo casovy, resp. kde je vhodnejsie sieti pridat nejaky vnutorny stav, reprezentovany pomocou spoja, ktory vedie spat:
  - predikcia casovych radov
  - strojovy preklad
  - rozpoznavanie reci
  - generovanie textu

### VysvÄ›tlit trÃ©novÃ¡nÃ­ rekurentnÃ­ch sÃ­tÃ­ pomoci algoritmu zpÄ›tnÃ©ho Å¡Ã­Å™enÃ­ v Äase

- Klasicky backpropagation algoritmus priamo nefunguje, lebo vahy sa opakovane pouzivaju v case. Riesenie je rozvinut siet v case - vytvorit si kopiu siete pre kazdy casovy krok.

### VysvÄ›tlit problÃ©m s explodujÃ­cÃ­mi a mizejÃ­cÃ­mi gradienty

- Pri backpropagation through time (BPTT) sa gradienty opakovane nasobia tymi istymi vahami v kazdom kroku (ak ide o rekurentnu vahu), to sposobuje:
  - explodujuce gradienty: ak vahy > 1 -> gradienty rastu exponencialne
  - miznuce gradienty: ak vahy < 1 -> gradienty klesnu k nule
 
- riesenie: bud pouzijeme Echo State siete alebo sa rekurentna vaha zafixuje na 1 a praca so stavom siete sa prevadza explicitne ako v Long-short term memory sietach

### Popsat princip Echo State sÃ­tÃ­

- specialny typ rekurzivnych neuronovych sieti

- hned na vstupe maju velku rekurentnu vrstvu s nahodnymi fixnymi vahami, ktore sa dalej netrenuju

- typicky je tato vrstva implementovana ako jedina matica $k x m$, kde $k = n+m$, $m$ je velkost rekurentnej vrstvy a $n$ je pocet vstupov

- tradicne ESN po rekurentnej vrstve obsahuje uz len jednu vrstvu, ktoru podobne ako u RBF sieti mozeme trenovat pomocou linearnej regresie

### Popsat trÃ©novÃ¡nÃ­ Echo State sÃ­tÃ­

- siet dostane vektory dlzky $n$ a pripoji k nim svoj vnutorny stav dlzky $m$, na ten aplikuju svoju rekurentnu vrstvu a tym dostane novy vnutorny stav

### Popsat LSTM buÅˆku a architekturu LSTM sÃ­tÄ›

- nahradia kazdy neuron tzv. LSTM bunkou, ktora explicitne pracuje so svojim stavom a rekurentne spoje medzi jednotlivymi bunkami potom maju vahu zafixovanu na 1

- vstupom kazdej bunky je jej stav $c_{t-1}$ z predosleho kroku a spojenie ich vystupov v predchadzajucom stave a novych vstupov $[h_{t-1}, x_t]$

- na zaklade vstupu sa najprv spocitaju hodnoty tzv. bran (gates) - zapominacia $f_t$ (forget - rozhodne, co z predosleho stavu sa zabudne) a vstupni $i_t$ (input - co nove sa zapise do stavu)

- // TODO: vzorce

### VysvÄ›tlit vÃ½hody Echo State sÃ­tÃ­ a LSMT sÃ­tÃ­ v porovnÃ¡nÃ­ se zÃ¡kladnÃ­mi rekurentnÃ­mi sÃ­tÄ›mi

- no asi najvacsia vyhoda je prave ta, ze sa dokazeme vyhnut explodujucim a miznucim gradientom

-------------------
## 12. Neuroevoluce
-------------------

### Popsat pouÅ¾itÃ­ evoluÄnÃ­ch algoritmÅ¯ pro trÃ©novÃ¡nÃ­ vah v neuronovÃ© sÃ­ti

- Majme nejaku doprednu neuronovu siet

- Ak chceme pouzit evolucne algoritmy, vpodstate pojde o problem spojitej optimalizacie, kde musime dodrzat postup:
  - Populacia: Kazdy jedinec je nejaky vektor realnych cisel
  - Geneticke operatory:
    - Mutacia: ku kazdemu genu sa pripocita nahodna hodnoa z normalneho rozdelenie
    - Krizenie: sa nepouziva, pretoze ich adaptacia moze byt dost velka
  - Fitness funkcia: jedine sa ohodnoti podla vykonu siete (napr. skore v hre)
 
- vyhody oproti gradiennym metodam:
  - lepsia paralelizacia
  - hodi sa pre prostredie s riedkymi odmenami
  - nevyzadujeme vypocet derivacii
   
### Popsat algoritmus NEAT - reprezentace jedince, operÃ¡tory

- evolvuje vahy aj topologiu siete naraz
- reprezentacia jedinca:
  - je reprezentovany zoznamom, ktory v kazdom gene obsahuje informacie:
    - odkial ide
    - kam vedie
    - hodnota, resp. vaha
    - priznak, ci je spoj aktivny
    - inovacne cislo

- inicializacia siete:
  - NEAT zacina z minimalnych struktur (neuronovych siti), ktore neobsahuju ziadne skryte neurony a potom sa rozsiruje
      
- geneticke operatory:
  - mutacia:
    - pridanie hrany: nahodne spoji dva neurony, ak spoj este neexistuje
    - pridanie neuronu: rozdeli existujuci spoj, deaktivuje ho, prida novy neuron a dve nove hrany
 
  - krizenie: robi sa pomocou invoacnych cisel:
    - dvaja jedinci, ktori sa maju krizit sa zarovnaju podla inovacnych cisel
    - hrany s rovnakym inovacnym cislom, ktore su u oboch jedincov sa dedia nahodne z jedneho alebo druheho
    - hrany, ktore su iba v jednom z jedincov sa dedia z toho lepsieho z tych dovch
    - to, ci su hrany aktivne alebo neaktivne sa rozhodne podla zdedenej hrany s nejakou pravdepodobnostou

- rozdelenie populacie na viacej druhov:
  - jedinci kazdeho druhu explciitne zdielaju fitness, teda fitness kazdeho jedinca je vydelena poctom jedincov rovnakeho druhu a tym sa dava novo objavenym myslienkam (strukturam) cas pre to, aby sa vylepsily pomocou genetickych operatorov 

### VysvÄ›tlit vÃ½znam inovaÄnÃ­ch ÄÃ­sel v algoritmu NEAT

- inovacne cislo je identifikator kazdej hrany, urceny podla poradia, v ktorom vznikol pocas mutacii. Sluzi na:
  - zarovannie rodicov pri krizeni
  - rozlisenie medzi starymi a novymi mutaciami

### Popsat myÅ¡lenku algoritmu HyperNEAT

- HyperNEAT je rozsirenie NEAT, ktore oddeluje vyvoj topologie siete od vypoctu konkretnych vah

- myslienka:
  - neuronova siet, kroru chceme vytvorit ma fixnu topologiu na zaciatku (napr. mriezku/hyper-kocka)
  
  - vahy sa reprezentuju pomocou inej neuronovej siete
    - tato siet dostava na vstup suradnice neuronov vo vyslednej sieti a vracia pre ne priamo vahy
    - siet pre vypocet vah sa potom vytvara pomocou NEATu

### Popsat rozÅ¡Ã­Å™enÃ­ algoritmu NEAT pro hledÃ¡nÃ­ architektur neuronovÃ½ch sÃ­tÃ­ (algoritmus coDeepNEAT)

- hladame celu strukturu neuronovych sieti

- z hladiska evolucnych algoritmov je potom potreba zakodovat strukturu siete (na urovni vrstiev alebo blokov) do jedinca

- v pripade vrstiev by stacilo, ak by bol jedinec napr. postupnost tychto vrsiev vratane ich parameterov

- operatory su potom upravy parametrov tychto vrstiev, pridanie dalsiej vrstvy, alebo pridanie spojenia medzi vrstvami, ktore spolu nesusedia

- algoritmus CoDeepNEAT koduje jedinca podobne ako NEAT. Rozdiel je v tom, ze jednotlive uzly neobsahuju jednotlive neurony, ale priamo moduly neuronovej siete (bloky neuronov)

- tieto moduly su taktiez vytvarane pomocou NEAT algoritmu

- pri vyhodnocovani fitness sa celkovy jedinec vytvori pomocou kombinacie tychto modulov, tak, ako je popisane v jedincovi.

### VysvÄ›tlit myÅ¡lenku algoritmu novelty search

- princip je vynechanie fitness funkcie, ktora by priamo hodnotila kvalitu najdeneho riesenia

- tato fitness funkcia je nahradena funkciou, ktora porovnava chovanie vytvorenych jedincov (napr. v bludisku vzdialenost start/end pozicii)

### Porovnat novelty search a evoluÄnÃ­ algoritmy a diskutovat jejich vÃ½hody/nevÃ½hody

- Vyhody novelty searchu: vyhyba sa lokalnym optimam fitness funkcie, podporuje diverzitu

- Vyhody evolucnych algoritmov: ma silne spojenie s cielovou ulohou

----------------------------------
## 13. HlubokÃ© zpÄ›tnovazebnÃ­ uÄenÃ­
----------------------------------

### VysvÄ›tlit algoritmus hlubokÃ©ho Q-uÄenÃ­

- rovnaka myslienka ako u Q-ucenia, tj. chceme pre kazdy stav $s$ a kazdu akciu $a$ odhadnut aku diskontovanu odmenu by sme dostali, ak by sme v stave $s$ vykonali akciu $a$. V klasickom Q-uceni tieto hodnoty boli reprezentovane ako matice Q, tato reprezentacia je problematicka, ak je vela stavov alebo vela akcii. V hlbokom Q-uceni sa teda pre reprezentaciu tejto matice pouziva neuronova siet, ktora pre kazdy stav vrati ohodnotenie vsektych akcii.

- ciel je naucit agenta policy, ktora maximalizuje ocakavanu diskontovanu odmenu v prostredi MDP (Markov decision problem) pomocou aproximacie Q-funkcie neuronovou sietou

### Porovnat Q-uÄenÃ­ a hlubokÃ© Q-uÄenÃ­

- Q-ucenie aproximuje hodnotovu funkciu pomocou tabulky, zatial co hlbkoe Q-ucenie pouziva neuronovu siet

- Q-ucenie funguje fajn pre male a diskretne priestory, hlboke funguje aj pre vacsie

### Popsat triky s experience replay a target network

- target network:
  - podstatou je, ze oddelime siet pre vyber akcie a siet pre odhad hodnoty
  - typicky len tak, ze sa zafixuju parametre siete, podla ktorej sa vybera akcia a menime len tie parametre siete, ktora sa uci ohodnocovanie

- experience replay:
  - podstatou je, ze si pamatame stvorice $(s,a,r,s')$ stavu,akcie,odmeny a nasledujuceho stavu a pri trenovani nahodne vyberiem prechody z tejto pamati miesto toho, aby sme vzdy pouzivali posledny prechod

### VysvÄ›tlit vliv experience replay a target network na hlubokÃ© Q-uÄenÃ­

- zachovanie vacsej stability pri trenovani

### Popsat algoritmus DDPG

- myslienka je taka, ze ak mame priestor akcii spojity (napr. riadenie auta, kde akcia je uhol otocenia volantu a stlacenie plynu/brzdy), tak mame velmi vela akcii, co je velmi zlozite na vyratanie maxima. Preto existuje algoritmus DDPG, ktory nahradi tuto operaciu novou sietou, ktora priamo vrati akciu, ktora sa ma previest

- myslienka trenovania je taka, ze chceme aby algoritmus vratil akciu, ktora maximalizuje $Q_Î¸ (s,a)$

- pouziva experience replay a target network

### Popsat actor-critic pÅ™Ã­stupy

- idea kombinuju vyhody policy gradientu a hodnotovych metod

- $G_t$ moze mat velky rozptyl -> nestabilne ucenie

- preto nahradime $G_t$ inymi vyrazmi, jedna moznost je priamo hodnota $Q(s,a)$, druha je napr. advantage

### Popsat advantage a zdÅ¯vodnit, proÄ se pouÅ¾Ã­vÃ¡

- spocita sa ako rozdiel medzi prevedenim akcie $a_t$ v stave $s_t$ a hodnotou stavu: $V(s_t) - A(s_t, a_t) = Q(s_t, a_t) - V(s_t)

- pocitame teda o kolko je lepsie vykonat akciu $a_t$ oproti nejake obecnej akcii. 

### Popsat metodu A3C

- nahradzuje pouzitie experience replay tym, ze sa hraje viacero hier naraz, aktualizacia vah sa potom priemeruje cez aktualizacia spocitane v vsetkych nezavislych hrach

----------------------------------
## 14. Particle Swarm Optimization
----------------------------------

- algoritmus pre spojitu optimalizaciu

- inspirovany chovanim ryb/vtakov

- populacia je reprezentovana ako mnozina castic

### Popsat aktualizaci poloh a rychlostÃ­ v PSO

- Kazda castica (particle) ma svoju poziciu $x$, rychlost $v$, najlepsiu najdenu poziciu $p_{best}$ a najlepsiu poziciu celej populacie $g_{best}$

- Algoritmus potom prebieha tak, ze sa castice pohybuju v priestore a pritom su pritahovane k miestam, kde nasla svoje najlepsie riesenie a globalne najlepsie riesenia

- Inicializujeme nahodnu pociatocnu populaciu castic a iterative aktualizujeme rychlosti a pozicie vsetkych castic podla rovnic:
  - $v$ <- $Ï‰v + Ï†_p r_p(p_{best} - x) + Ï†_b r_b(g_{best} - x)$
  - $x$ <- $x + v$
 
- kde $r_p$, $r_b$ su nahodne cisla medzi 0 a 1
- $Ï‰$, $Ï†_p$, $Ï†_b$ su parametre, ktore urcuju zotrvacnost a ako velmi je jedinec pritahovany k svojmu a ku globalnemu najlepsiemu rieseniu

### Popsat topologie pouÅ¾Ã­vanÃ© v PSO (globÃ¡lnÃ­, geometrickÃ©, sociÃ¡lnÃ­)

- topologia urcuje, ktore casti si medzi sebou dokazu komunikovat a zdielat o sebe informacie

- globalna topologia:
  - Vsetky castice mozu priamo komunikovat so vsetkymi (a sdielat informaciu o globalnom optime)
  
- geometricka topologia:
  - Spolu komunikuju castice, tkore su blizko u seba

- socialna topologia:
  - Topologia je urcena predom, bez ohladu na pozicie castic, napr. kruhova topologia, kde kazda castica ma iba dvoch susedov

### VysvÄ›tlit vliv topologiÃ­ na algoritmus PSO

- Globalna zaistuje rychlu konvergenciu, ale castice casto sa dostanu len do lokalneho minima

- Geometricke a socialne, viac hejn, vacsia diverzita, nevyhoda ale je ze im to trva trocha dlhsie, teda pomalsia konvergencia

### VysvÄ›tlit pouÅ¾itÃ­ PSO pro Å™eÅ¡enÃ­ problÃ©mÅ¯ ve spojitÃ© optimalizaci

- Pozicie castic priamo reprezentuju kandidatov na riesenie

- Kvalita kandidatov je urcena podla hodnoty optimalizovanej funkcie - fitness funkcia sa rata pre kazdu casticu na zaklade jej pozicie

------------------------------
## 15. Ant Colony Optimization
------------------------------

### VysvÄ›tlit zÃ¡kladnÃ­ pojmy ACO - feromon, atraktivita

- zalozeny na chovani mravcov

- Feromon $ğœ_{xy}$: mnozstvo latky na hrane (x,y), ktore urcuje, ako casto bola hrana vyuzivana mravcami, ktori nasli dobre riesenie. Pohyb funguje tak, ze mravec poklada male mnozstvo feromonu, ak najde poravu, tak sa vracia do mraveniska a ide znova za potravou, ale poklada ovela vacsie mnozstvo feromonu.

- Atraktivita $Î½_{xy}$: heuristicka hodnota prechodov medzi vrcholmi, cim vyssia tym lepsia

- algoritmus bezi iterativne - vygenerovanie riesenia a update feromonu

### Popsat generovÃ¡nÃ­ Å™eÅ¡enÃ­ pomocÃ­ ACO

- Kazdy mravec zacne v nahodnom uzle grafu

- Postupne si vybera dalsi uzol na zaklade pravpodobnosti prechodu z vrcholu $x$ do vrcholu $y$, ktora zavisi na mnozstve feromonu $ğœ_{xy}$ medzi tymito dvoma vrcholmi a atraktivite 

- Pravdepodobnnost prechode je umerna hodnote $(ğœ_{xy}^Î±)(Î½_{xy}^Î²)$, kde $Î±$ je konstanta reprezentujuca vahu feromonu a $Î²$ je konstanta reprezentujuca vahu atraktivity 

### Popsat aktualizaci feromonu na zÃ¡kladÄ› kvality nalezenÃ©ho Å™eÅ¡enÃ­

- Update feromonu ma dva kroky - vyparenie feromonu a polozenie noveho feromonu

- Vyparenie feromonu:
  - $ğœ_{xy}$ <- $(1-Ï)ğœ_{xy}$, kde Ï je konstanta, ktora urcuje rychlost vyparenia feromonu z intervalu [0,1] 

- Polozenie noveho feromonu, ktore odpoveda kvalite riesenia najdenych mravcov:
  - $ğœ_{xy}$ <- $\sum_k ğœ_{xy}^k$, kde $Q$ je vhodne zvolena konstanta a $L_k$ je kvalita riesenie najdeneho mravcom $k$ a $ğœ_{xy}^k = \frac{Q}{L_k}

### Popsat pouÅ¾itÃ­ ACO pro Å™eÅ¡enÃ­ problÃ©mu obchodnÃ­ho cestujÃ­cÃ­ho a vehicle routing problÃ©mu

- TSP:
  - Uzly = mesta
  - Hrany = cesty medzi mestami
  - $L_k$ je typicky dlzka cesty
  - atraktivita $Î½_{xy}$ je prevratena hodnota dlzky hrany (x,y)

- VHP:
  - riesi sa velmi podobne ako TSP, ale s viacerymi vozidlami a obmedzeniami (napr. kapacita vozidla)
  - Feromony a heuristika sa vyuzivaju rovnako
  - Jediny rozdiel je v generovani cesty mravcom, mame tam obmedzenie na kapacitu, tak len pridame, ze ak presiahneme kapacitu, tak sa vratime do skladu

-----------------------
### 16. Artificial Life
-----------------------

- zabyva sa systemami, ktore pripominaju skutocny zivot
- cielom je pochopit ako zivot funguje a komunikuje, pripadne zivot vytvorit

### VysvÄ›tlit rozdÃ­ly mezi jednotlivÃ½mi typy umÄ›lÃ©ho Å¾ivota (soft, hard, wet)

- Soft Alife (softwarovy):
  - vyuziva pocitacove simulacie, v ktorych sa modeluje chovanie organizmov a ich interakcie (napr. celularne automaty, Tierra, Game of Life
  - cielom je pochopit principy zivota a evolucie cez simulacie

- Hard Alife (hardwarovy):
  - zameriava sa na konstrukciu fyzickych robotv alebo zariadeni, ktore napodobnuju zivotne chovanie (napr. roboty)
  - cielom je vytvorit embodiment zivota

- Wet Alife (mokry):
  - pracuje s biochemickymi latkami a experimentuje s tvorbou zivota na chemickej urovni (napr. pokusy vytvorit umelu DNA)
  - inspiruje sa prirodnou biochemiou a usiluje sa o nove formy zivota na molekularnej urovni

### VysvÄ›tlit rozdÃ­ly mezi silnÃ½m a slabÃ½m umÄ›lÃ½m Å¾ivotem

- weak Alife:
  - Hovori, ze zivot nie je mozne vytvorit mimo biologicky kontext
  - Simulacie su iba nastroje ku studiu zivota, ale nie su zive sami o sebe

- strong Alife:
  - Hovori, ze zivot je formalny proces, ktory moze existovat v lubovolnom mediu
  - napr. softwarovy organizmus moze byt povazovany za zivy, ak vykazuje potrebne vlastnosti zivota (reprodukcia, vyvoj,...)

### Popsat 1D a 2D celulÃ¡rnÃ­ automaty

- Celularni automat je diskretny model, tvoreny mriezkou buniek, kazda bunka ma stav (napr. farba) a ten sa aktualizuje podla pravidiel podla stavov ich susedov

- 1D celularny automat:
  - Mriezka je jednorozmerna

- 2D celularny automat:
  - Bunky tvoria 2D mriezku

### Popsat pravidla Game of Life

- 2D celularni automat s dvoma stavmi (ziva/mrtva bunka)
- Pravidla:
  - Ziva bunka s 2 alebo 3 zivymi susedmi preziva
  - Ziva bunka s menej ako 2 alebo viac ako 3 zivymi susedmi umiera
  - Mrtva bunka s prave 3 zivymi susedmi ozije

### Popsat pravidla Langtonova mravence

- Je to mravec, ktory sa pohybuje na 2D mriezke s dvoma farbami

- Pri kazdom pohybe mravec prefarbi svoje policko na opacnu farbu a v zavisosti na povodnej farbe policka sa rozhodne ci sa ma otocit doprava/dolava

### VysvÄ›tlit pojem dÃ¡lnice u Langtonova mravence

- Mravec na zaciatku sa hybe podla pravidiel a jednoducho, potom sa ale zacne chovat chaoticky a pseudonahodne.
  
- Nakoniec ale zacne opakovat postupnost 104 krokov, ktore tvoria tzv. dialnicu: mravec tym uteka stale jednym smerom na nekonecna

### Popsat systÃ©m Tierra

- system Tierra simuluje zivot pocitacovych programov
- je implementovana ako emulator jednoducheho pocitacoveho kodu s 32 roznymi instrukciami
- tieto instrukcie obsahuju jednoduche aritmeticke instrukcie, podmienky, skoly a dva typy no-op - NOP0 a NOP1 - tie sa pouzivaju na definovanie cielov skokov
- simulacia zacina s jednym jedincom, ktory sa dokaze sam skopirovat

### Popsat jedince v systÃ©mu Tierra

- jedinec je program zlozeny z instrukcii
- ma svoj vlastny virtualny procesor

### VysvÄ›tlit zpÅ¯sob adresovÃ¡nÃ­ (definovÃ¡nÃ­ cÃ­lÅ¯ skoku) v systÃ©mu Tierra

- nepouziva absolutne alebo relativne adresy pre skoky
- miesto toho poziva instrukcie NOP0 a NOP1 ako definovanie cielov skokov
- ak mame niekde instrukciu pre skok, nasleduje po nej niekolko NOPx instrukcii, pri skoku potom hladame najblizsie miesto v pamati, kde je komplementarna postupnost instrukcii (NOP0 je komplementrana k NOP1 a naopak)

### Popsat pÅ™Ã­klady vytvoÅ™enÃ½ch jedincÅ¯ v sytÃ©mu Tierra (paraziti)

- simulacia zacina s jednym jedincom, ktory sa dokaze skopirovat

- pri kopirovani je mala sanca, ze dojde k mutacii bitu v jedinci, tym ale mozu vzniknut novi, niektori su zaujimavi:
  - paraziti: neobsahuju vlastnu kopirovaciu proceduru, ale ak populacia obsahuje jedincov s touto procedurou, tak paraziti preziju
 
  - jedinci, ktori sa dokazu branit parazitom
 
  - hyper-paraziti: presvedcia parazita, abz kopiroval ich miesto seba
